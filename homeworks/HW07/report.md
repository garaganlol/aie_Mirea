# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите):
S07-hw-dataset-01.csv
S07-hw-dataset-02.csv
S07-hw-dataset-03.csv

### 1.1 Dataset A
- Файл: `S07-hw-dataset-01.csv`
- Размер: 12000 строк, 9 столбцов (включая sample_id)
- Признаки: Все 8 признаков (f01-f08) числовые
- Пропуски: Нет пропусков
- "Подлости" датасета: 
  - Признаки в разных шкалах с разными диапазонами значений
  - Наличие шумовых признаков, мешающих кластеризации
  - Без масштабирования результаты будут неверными

### 1.2 Dataset B
- Файл: `S07-hw-dataset-02.csv`
- Размер: 8000 строк, 4 столбца (включая sample_id)
- Признаки: Все 3 признака (x1, x2, z_noise) числовые
- Пропуски: Нет пропусков
- "Подлости" датасета:
  - Наличие шумового признака `z_noise`
  - Нелинейная структура данных
  - Выбросы, которые могут мешать кластеризации

### 1.3 Dataset C
- Файл: `S07-hw-dataset-03.csv`
- Размер: 15000 строк, 5 столбцов (включая sample_id)
- Признаки: Все 4 признака (x1, x2, f_corr, f_noise) числовые
- Пропуски: Нет пропусков
- "Подлости" датасета:
  - Присутствует коррелированный признак `f_corr`
  - Шумовой признак `f_noise`
  - Кластеры разной плотности и размера

## 2. Protocol

### Препроцессинг
Для всех датасетов использован одинаковый пайплайн препроцессинга:
1. **Выделение признаков**: Удаление столбца `sample_id`
2. **Масштабирование**: Применение `StandardScaler` для всех признаков
3. **Обработка пропусков**: Не требовалась (пропусков нет)
4. **Кодирование категориальных признаков**: Не требовалось

### Поиск гиперпараметров
- **KMeans**: 
  - Диапазон k: от 2 до 15-20 в зависимости от датасета
  - Фиксированные параметры: `n_init=10`, `random_state=42`
  - Критерий выбора: максимизация silhouette score
- **DBSCAN**:
  - Подбор `eps` через k-distance plot
  - Фиксированный `min_samples=5`
  - Критерий выбора: максимизация silhouette score с учетом доли шума

### Метрики качества
Рассчитывались три внутренние метрики:
1. **Silhouette Score** (выше = лучше)
2. **Davies-Bouldin Index** (ниже = лучше)  
3. **Calinski-Harabasz Score** (выше = лучше)

Для DBSCAN метрики рассчитывались только на нешумовых точках (кластеры с label ≠ -1).

### Визуализация
- **PCA(2D)**: Обязательная визуализация для лучшего алгоритма каждого датасета
- Объясненная дисперсия PCA: от 68.86% до 75.91%

## 3. Models

На каждом датасете сравнивались:

### 3.1 Dataset_01
- **KMeans**: Подбор k в диапазоне 2-15
- **DBSCAN**: Подбор eps с min_samples=5

### 3.2 Dataset_02  
- **KMeans**: Подбор k в диапазоне 2-15
- **DBSCAN**: Подбор eps с min_samples=5

### 3.3 Dataset_03
- **KMeans**: Подбор k в диапазоне 2-20
- **DBSCAN**: Подбор eps с min_samples=5

## 4. Results

### 4.1 Dataset A
- **Лучший метод**: DBSCAN
- **Параметры**: eps=0.1369, min_samples=5
- **Метрики**:
  - Silhouette: 0.6587
  - Davies-Bouldin: 0.4550  
  - Calinski-Harabasz: 243.42
- **Доля шума**: 99.78%
- **Комментарий**: DBSCAN показал значительно лучшие метрики качества (silhouette 0.66 vs 0.52 у KMeans), однако почти все точки были помечены как шум. Это может указывать на отсутствие четко выраженных плотных кластеров в данных.

### 4.2 Dataset B
- **Лучший метод**: DBSCAN
- **Параметры**: eps=0.0474, min_samples=5
- **Метрики**:
  - Silhouette: 0.9442
  - Davies-Bouldin: 0.0697
  - Calinski-Harabasz: 8558.76
- **Доля шума**: 99.75%
- **Комментарий**: DBSCAN показал исключительно высокий silhouette score (0.94), что свидетельствует о хорошем разделении кластеров. Однако, как и в Dataset_01, почти все точки отнесены к шуму, что может быть связано с нелинейной структурой данных.

### 4.3 Dataset C
- **Лучший метод**: DBSCAN
- **Параметры**: eps=0.0693, min_samples=5
- **Метрики**:
  - Silhouette: 0.7557
  - Davies-Bouldin: 0.3024
  - Calinski-Harabasz: 332.78
- **Доля шума**: 99.85%
- **Комментарий**: DBSCAN снова показал лучшие метрики по сравнению с KMeans. Высокая доля шума (99.85%) может указывать на то, что кластеры имеют очень низкую плотность или данные преимущественно состоят из фонового шума.

## 5. Analysis

### 5.1 Сравнение алгоритмов

**Наблюдения:**
1. **DBSCAN vs KMeans**: Во всех трех датасетах DBSCAN показал значительно лучшие значения silhouette score по сравнению с KMeans.
2. **Проблема с шумом**: DBSCAN помечал 99.7-99.8% точек как шум, что делает найденные кластеры практически неинформативными.
3. **Влияние параметров**: Подбор параметра `eps` оказался критически важным для DBSCAN. Слишком маленькие значения приводили к помещению всех точек в шум, слишком большие - к созданию одного большого кластера.
4. **Масштабирование**: Было обязательным для всех датасетов, так как признаки имели разные масштабы.

**Выводы:**
- KMeans оказался более стабильным, но давал худшие метрики качества
- DBSCAN показал хорошие метрики, но выделял слишком много шума
- Возможно, данные специально сконструированы так, чтобы продемонстрировать слабые стороны обоих алгоритмов

### 5.2 Устойчивость (обязательно для одного датасета)

**Проверка устойчивости для Dataset A (dataset-01):**
- Метод: 5 запусков KMeans с разными random_state
- Метрика: Adjusted Rand Index (ARI) между парами разбиений
- Результаты:
  - Средний ARI: 0.0008 (очень низкий)
  - Стандартное отклонение: 0.0054
  - Диапазон ARI: от -0.0077 до 0.0087

**Вывод:** Кластеризация KMeans показала очень низкую устойчивость - разные запуски давали практически несравнимые разбиения. Это может быть связано с:
1. Перекрывающимися кластерами в данных
2. Отсутствием четкой кластерной структуры
3. Чувствительностью KMeans к инициализации центроидов

### 5.3 Интерпретация кластеров

**Сложности интерпретации:**
1. **Высокая доля шума**: DBSCAN пометил 99.7-99.8% точек как шум, что делает оставшиеся кластеры статистически незначимыми
2. **Нестабильность KMeans**: Разные запуски KMeans давали разные разбиения, что затрудняет содержательную интерпретацию
3. **Отсутствие предметной области**: Синтетические данные не имеют предметной интерпретации

**Наблюдения:**
- Визуализация PCA показала, что точки в основном равномерно распределены в пространстве признаков
- Отсутствуют четко выраженные сгустки точек, что объясняет высокую долю шума в DBSCAN
- KMeans насильно делит данные на кластеры, но это деление не соответствует естественной структуре данных

## 6. Conclusion

1. **Масштабирование критически важно**: Без стандартизации признаков алгоритмы, основанные на расстояниях (KMeans, DBSCAN), дают некорректные результаты.

2. **DBSCAN чувствителен к параметрам**: Подбор `eps` и `min_samples` требует тщательного анализа данных и может значительно влиять на результаты.

3. **Метрики не всегда отражают качество**: DBSCAN показал высокие значения silhouette, но при этом поместил 99.7% точек в шум. Это демонстрирует, что внутренние метрики нужно интерпретировать с осторожностью.

4. **Визуализация помогает понять структуру данных**: PCA показал отсутствие четких кластеров в данных, что объясняет проблемы обоих алгоритмов.

5. **KMeans неустойчив на данных без четкой структуры**: Проверка устойчивости показала, что разные запуски KMeans дают совершенно разные разбиения.

6. **Синтетические данные могут быть "подлыми"**: Даже при хороших метриках алгоритм может давать непрактичные результаты (как DBSCAN с 99.7% шума).

7. **Важность комплексной оценки**: Нельзя полагаться только на одну метрику или один алгоритм. Необходимо использовать несколько метрик, визуализацию и содержательный анализ результатов.

8. **Реальная ценность кластеризации** - в интерпретируемости результатов, а не только в численных метриках. Если алгоритм не может выделить содержательные кластеры, его практическая польза ограничена.