# Отчёт по итоговому проекту по курсу «Инженерия Искусственного Интеллекта»

> Рекомендуемый объём отчёта: 3-5 страниц в эквиваленте Markdown/печатного текста.  
> Отчёт должен позволить преподавателю понять задачу, данные, выбранные модели и результаты экспериментов.

---

## 1. Паспорт проекта

- **Название проекта:** `<краткое название, 1-2 строки>`
- **Автор:** `Ветошников Глеб Юрьевич`
- **Группа:** `БФБО-02-23`
- **Контакт:** `@garagant`
- **Ссылка на репозиторий:** `https://github.com/garaganlol/aie_Mirea`

Цель проекта - разработать алгоритм персональных рекомендаций для пользователей Steam. Используется открытый обезличенный датасет с kaggle `Game Recommendations on Steam`, простые модели контентной фильтрации и baseline-модели на конкретных признаках. В результате проекта по идентификатору пользователя (user_id) система должна предсказать,какие игры ему понравятся на основе его прошлого поведения и поведения похожих пользователей.
---

## 2. Постановка задачи и контекст


### 2.1 Предметная область и задача:
Проект относится к предметной области **персональных рекомендательных систем для цифрового контента** на примере платформы Steam.
Решаемая задача — **персональная рекомендация игр пользователям** на основе их исторического поведения и взаимодействий с платформой.

Потенциальный пользователь сервиса — игрок Steam, который:

* уже играл в некоторое количество игр,
* оставлял отзывы или имеет зафиксированное игровое время,
* ищет новые игры, которые с высокой вероятностью ему понравятся.

Сценарий использования: пользователь открывает рекомендации («Что поиграть дальше?»), сервис анализирует его историю и возвращает список релевантных игр. Аналогичный сценарий применим для витрины онлайн-магазина или блока персонализированных рекомендаций.

### 2.2 Формулировка задачи в терминах ML/ИИ:
Задача формулируется как **recommendation problem с implicit feedback**.

**Входные данные:**

* идентификатор пользователя (`user_id`);
* история взаимодействий пользователя с играми:

  * `app_id`,
  * флаг `is_recommended`,
  * время в игре (`hours`),
  * дополнительные признаки отзывов (`helpful`, `funny`);
* метаданные игр (название, цена, рейтинг, платформы).

**Выход модели:**

* упорядоченный список из *N* рекомендованных игр для заданного пользователя;
* оценка релевантности (score) для каждой рекомендации.

**Целевая переменная:**

* скрытая (implicit) предпочтительность пользователя к игре, аппроксимируемая через поведение (время игры, рекомендации, отзывы).

**Ограничения и требования:**

* модель должна масштабироваться на десятки тысяч пользователей и игр;
* время ответа сервиса должно быть достаточным для онлайн-использования (миллисекунды–секунды);
* допускается ограниченная интерпретируемость (через похожие игры или пользователей);
* модель должна корректно работать с разреженными данными и учитывать проблему cold start.

---

### 2.3 Целевые метрики качества:
Для offline-оценки качества рекомендаций используются:

* **Precision@K** — показывает, какая доля рекомендованных игр действительно релевантна пользователю;
* **Recall@K** — измеряет, какую часть интересных пользователю игр модель смогла предложить;
* **NDCG@K** — учитывает не только факт попадания релевантных игр в рекомендации, но и их позицию в выдаче.

Данные метрики выбраны, потому что:

* задача не является классификацией или регрессией в классическом смысле;
* важен порядок рекомендаций, а не только их наличие;
* они являются стандартом для оценки рекомендательных систем с implicit feedback.

## 3. Данные

Опишите, какие данные использует проект:

1. **Источник данных:**
   - открытый датасет (ссылка на источник);
   - синтетические данные;
   - обезличенные данные и т.п.

2. **Структура данных:**
   - какие есть таблицы/файлы;
   - какие ключевые признаки (колонки);
   - какого типа данные (числовые, категориальные, текст, изображения и т.п.).

3. **Предобработка и EDA:**
   - какие основные шаги предобработки выполнялись (очистка, фильтрация, нормализация, токенизация, выделение признаков и т.д.);
   - какие важные наблюдения из разведочного анализа данных (несбалансированность классов, пропуски, выбросы и т.п.).

Укажите, в каких ноутбуках лежат основные шаги EDA и подготовки данных (например, `notebooks/01_eda.ipynb`).

---

## 4. Модели и подходы

Опишите, какие модели вы пробовали и как развивался ваш подход:

1. **Базовые (baseline) модели:**
   - какие простые модели/подходы были использованы в качестве baseline;
   - какие результаты они показали (по ключевым метрикам).

2. **Улучшенные модели и эксперименты:**
   - какие модели, архитектуры или настройки были добавлены поверх baseline;
   - какие гиперпараметры/настройки оказались важными;
   - какие эксперименты вы проводили (например, фичи, архитектуры, регуляризация, обучающие режимы).

3. **Нейросетевые модели (если применимо):**
   - какие архитектуры использовались;
   - какие были особенности обучения (размер батча, lr, scheduler, augmentations и т.д.).

Ссылайтесь на конкретные ноутбуки с экспериментами (например, `notebooks/02_baselines.ipynb`, `notebooks/03_models_tuning.ipynb`).

---

## 5. Экспериментальный протокол и результаты

Здесь важно показать, что выбор финальной модели был осмысленным.

1. **Экспериментальный протокол:**
   - как вы делили выборку (train/val/test, k-fold и т.п.);
   - как считали метрики (на какой части данных, с какими параметрами).

2. **Сравнение моделей по метрикам:**

   Пример таблицы (адаптируйте под свои метрики):

   | Модель / конфигурация         | Описание                             | Метрика 1 | Метрика 2 | Комментарий              |
   |-------------------------------|--------------------------------------|-----------|-----------|--------------------------|
   | Baseline                      | LogisticRegression, стандартные фичи | 0.78      | 0.74      | Простая стартовая точка  |
   | Model A                       | CatBoost, базовые параметры          | 0.84      | 0.81      | Лучше по основным метрикам |
   | Model B                       | CatBoost, тюнинг гиперпараметров     | 0.86      | 0.83      | Финальная модель         |

3. **Выбор финальной модели:**
   - какая модель выбрана как финальная и почему (баланс точности, скорости, сложности);
   - какие trade-off’ы приходилось учитывать.

---

## 6. Архитектура решения и сервис

Опишите, как из модели получился работающий сервис:

1. **Архитектура пайплайна:**
   - как связаны между собой загрузка данных, предобработка, модель и сервис;
   - можно приложить простую схему (текстом или картинку).

2. **API и endpoints:**
   - какие endpoints реализованы (минимум: `/health`, `/predict`);
   - какие параметры принимает `/predict` и что возвращает.

3. **Технологический стек:**
   - какие библиотеки и фреймворки используются;
   - используется ли Docker, какие есть команды для поднятия сервиса.

---

## 7. Наблюдаемость, конфигурация и безопасность

Кратко опишите:

1. **Логи и наблюдаемость:**
   - что логируется (запросы, ошибки, важные события);
   - как можно понять, что сервис работает корректно.

2. **Конфигурации:**
   - какие параметры вынесены в конфиги (`configs/`, `.env.example`);
   - что можно перенастроить без изменения кода.

3. **Безопасность:**
   - как вы избегали коммита секретов (токенов, паролей);
   - нет ли в репозитории “чувствительных” данных.

---

## 8. Ограничения и дальнейшая работа

Будьте честны:

- какие у проекта есть ограничения (качество, скорость, устойчивость, объём данных и т.п.);
- что бы вы сделали, если бы было больше времени:
  - улучшения модели;
  - улучшения сервиса;
  - улучшения данных и экспериментов.

---

## 9. Сценарий демонстрации на защите

Опишите, как вы планируете демонстрировать проект:

1. Что вы **запускаете**:
   - сервис, ноутбук, скрипт и т.п.;
2. Какие **1-2 ключевых сценария** вы показываете:
   - пример запроса к `/predict`;
   - пример работы с реальными/демонстрационными данными;
3. На что хотите, чтобы преподаватель обратил внимание:
   - качество предсказаний;
   - устойчивость;
   - удобство API;
   - архитектуру.

Ссылайтесь на команды и инструкции из `project/README.md`.

---
